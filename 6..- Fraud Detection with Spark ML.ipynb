{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud detection using a Random Forest model\n",
    "\n",
    "Dr Jose M. Albornoz, May 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will build a classifier for fraud detection purposes using a Random Forest model. The dataset can be found at https://www.kaggle.com/ntnu-testimon/paysim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://DESKTOP-FQ2BOOJ:4040\n",
       "SparkContext available as 'sc' (version = 2.4.0, master = local[*], app id = local-1559745571045)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
       "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
       "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
       "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
       "import org.apache.spark.ml.classification.RandomForestClassifier\n",
       "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit, CrossValidator}\n",
       "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, OneHotEncoderEstimator}\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "import org.apache.spark.ml.Pipeline\n",
       "import org.apache.log4j._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator  \n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator  \n",
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics  \n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics  \n",
    "import org.apache.spark.ml.classification.RandomForestClassifier  \n",
    "import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit, CrossValidator}  \n",
    "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, OneHotEncoderEstimator}  \n",
    "import org.apache.spark.ml.linalg.Vectors  \n",
    "import org.apache.spark.ml.Pipeline  \n",
    "import org.apache.log4j._  \n",
    "Logger.getLogger(\"org\").setLevel(Level.ERROR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.- Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data: org.apache.spark.sql.DataFrame = [step: int, type: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").format(\"csv\").load(\"Data/paysim.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|step|    type|  amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "|   1| PAYMENT| 9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|\n",
      "|   1| PAYMENT| 1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|      0|             0|\n",
      "|   1|TRANSFER|   181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n",
      "|   1|CASH_OUT|   181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n",
      "|   1| PAYMENT|11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|      0|             0|\n",
      "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_length: Long = 6362620\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_length = data.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.- Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.- Class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numCasesFraud: Long = 8213\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numCasesFraud = data.filter($\"isFraud\" === 1).count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numCasesNotFraud: Long = 6354407\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numCasesNotFraud = data.filter($\"isFraud\" === 0).count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numCasesFraudPercent: Float = 0.12908204\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numCasesFraudPercent = numCasesFraud.toFloat*100/data_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numCasesNotFraudPercent: Float = 99.87092\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val numCasesNotFraudPercent = numCasesNotFraud.toFloat*100/data_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.- Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_null_count: org.apache.spark.sql.DataFrame = [step_nulls_count: bigint, type_nulls_count: bigint ... 9 more fields]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_null_count = data.select(data.columns.map(colName => {count(when(col(colName).isNull, true)) as s\"${colName}_nulls_count\"}): _*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+------------------+--------------------+-------------------------+--------------------------+--------------------+--------------------------+--------------------------+-------------------+--------------------------+\n",
      "|step_nulls_count|type_nulls_count|amount_nulls_count|nameOrig_nulls_count|oldbalanceOrg_nulls_count|newbalanceOrig_nulls_count|nameDest_nulls_count|oldbalanceDest_nulls_count|newbalanceDest_nulls_count|isFraud_nulls_count|isFlaggedFraud_nulls_count|\n",
      "+----------------+----------------+------------------+--------------------+-------------------------+--------------------------+--------------------+--------------------------+--------------------------+-------------------+--------------------------+\n",
      "|               0|               0|                 0|                   0|                        0|                         0|                   0|                         0|                         0|                  0|                         0|\n",
      "+----------------+----------------+------------------+--------------------+-------------------------+--------------------------+--------------------+--------------------------+--------------------------+-------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_null_count.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.- Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.- Transactions that empty an account, zero initial balance in destination account, and balance differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data1: org.apache.spark.sql.DataFrame = [step: int, type: string ... 13 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data1 = data.withColumn(\"emptiedAccount\", when($\"amount\" === $\"oldbalanceOrg\", lit(1)).otherwise(lit(0))).\n",
    "                 withColumn(\"zeroBalance\", when($\"oldbalanceDest\" === 0, lit(1)).otherwise(lit(0))).\n",
    "                 withColumn(\"originBalanceDiff\", $\"newbalanceOrig\" - $\"oldbalanceOrg\").\n",
    "                 withColumn(\"recipientBalanceDiff\", $\"newbalanceDest\" - $\"oldbalanceDest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.- Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.- Drop irrelevant columns, shuffle dataset, change label column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colsToRemove: Seq[String] = List(step, type, nameOrig, nameDest, isFlaggedFraud)\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val colsToRemove = Seq(\"step\", \"type\", \"nameOrig\", \"nameDest\", \"isFlaggedFraud\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.rand\n",
       "data2: org.apache.spark.sql.DataFrame = [amount: double, oldbalanceOrg: double ... 8 more fields]\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.rand\n",
    "val data2 = data1.drop(colsToRemove:_*).orderBy(rand()).orderBy(rand()).withColumnRenamed(\"isFraud\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- amount: double (nullable = true)\n",
      " |-- oldbalanceOrg: double (nullable = true)\n",
      " |-- newbalanceOrig: double (nullable = true)\n",
      " |-- oldbalanceDest: double (nullable = true)\n",
      " |-- newbalanceDest: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- emptiedAccount: integer (nullable = false)\n",
      " |-- zeroBalance: integer (nullable = false)\n",
      " |-- originBalanceDiff: double (nullable = true)\n",
      " |-- recipientBalanceDiff: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.- Assemble features vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_204cfe7000e4\n",
       "output: org.apache.spark.sql.DataFrame = [label: int, features: vector]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Set the input columns as the features we want to use\n",
    "val assembler = (new VectorAssembler().setInputCols(Array(\"amount\", \"oldbalanceOrg\", \n",
    "    \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\", \"emptiedAccount\", \"zeroBalance\", \n",
    "    \"originBalanceDiff\", \"recipientBalanceDiff\")).\n",
    "   setOutputCol(\"features\"))\n",
    "\n",
    "// Transform the DataFrame\n",
    "val output = assembler.transform(data2).select($\"label\",$\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, features: vector]\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, features: vector]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Splitting the data by create an array of the training and test data\n",
    "val Array(training, test) = output.select(\"label\",\"features\").randomSplit(Array(0.7, 0.3), seed = 801)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.- Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now create a model object (I’m using a Random Forest Classifier), define a parameter grid, create a Cross Validator object (here is where we set our scoring metric for training the model) and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_50246d962f4e\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create the model\n",
    "val rf = new RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\trfc_50246d962f4e-maxBins: 1000,\n",
       "\trfc_50246d962f4e-maxDepth: 5,\n",
       "\trfc_50246d962f4e-minInstancesPerNode: 30,\n",
       "\trfc_50246d962f4e-numTrees: 30\n",
       "})\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create the param grid\n",
    "val paramGrid = new ParamGridBuilder().addGrid(rf.maxBins, Array(1000)).\n",
    "                                       addGrid(rf.minInstancesPerNode, Array(30)).\n",
    "                                       addGrid(rf.numTrees, Array(30)).\n",
    "                                       addGrid(rf.maxDepth, Array(5)).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv: org.apache.spark.ml.tuning.CrossValidator = cv_35592471fe00\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// create cross val object, define scoring metric\n",
    "val cv = new CrossValidator().\n",
    "  setEstimator(rf).\n",
    "  setEvaluator(new BinaryClassificationEvaluator().setMetricName(\"areaUnderPR\")).\n",
    "  setEstimatorParamMaps(paramGrid).\n",
    "  setNumFolds(10).\n",
    "setParallelism(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.- Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.tuning.CrossValidatorModel = cv_35592471fe00\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// You can then treat this object as the model and use fit on it.\n",
    "val model = cv.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Array[Double] = Array(0.9965534672046898)\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: org.apache.spark.ml.Model[_] = RandomForestClassificationModel (uid=rfc_50246d962f4e) with 30 trees\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bestModel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.- Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little more difficult because the evaluation functionality still mostly resides in the RDD-API for Spark, requiring some different syntax. Let’s begin by getting predictions on our test data and storing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results: org.apache.spark.sql.DataFrame = [features: vector, label: int ... 1 more field]\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = model.transform(test).select(\"features\", \"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(9,[0,1,6,7],[327...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[368...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[464...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[522...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[565...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[566...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[636...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[864...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[951...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[117...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[122...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[147...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[152...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[155...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[161...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[169...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[178...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[181...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[182...|    0|       0.0|\n",
      "|(9,[0,1,6,7],[187...|    0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then convert these results to an RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictionAndLabels: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[906] at rdd at <console>:39\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionAndLabels = results.select($\"prediction\",$\"label\").as[(Double, Double)].rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create our metrics objects and print out the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "1905661.0  0.0     \n",
      "14.0       2464.0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bMetrics: org.apache.spark.mllib.evaluation.BinaryClassificationMetrics = org.apache.spark.mllib.evaluation.BinaryClassificationMetrics@6bc42e44\n",
       "mMetrics: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@99e0171\n",
       "labels: Array[Double] = Array(0.0, 1.0)\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Instantiate a new metrics objects\n",
    "val bMetrics = new BinaryClassificationMetrics(predictionAndLabels)\n",
    "val mMetrics = new MulticlassMetrics(predictionAndLabels)\n",
    "val labels = mMetrics.labels\n",
    "\n",
    "// Print out the Confusion matrix\n",
    "println(\"Confusion matrix:\")\n",
    "println(mMetrics.confusionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the numbers in the confusion matrix to calculate some useful metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision(0.0) = 0.9999926535217181\n",
      "Precision(1.0) = 1.0\n",
      "Recall(0.0) = 1.0\n",
      "Recall(1.0) = 0.9943502824858758\n",
      "FPR(0.0) = 0.005649717514124294\n",
      "FPR(1.0) = 0.0\n",
      "F1-Score(0.0) = 0.9999963267473663\n",
      "F1-Score(1.0) = 0.9971671388101983\n"
     ]
    }
   ],
   "source": [
    "// Precision by label\n",
    "labels.foreach { l =>\n",
    "  println(s\"Precision($l) = \" + mMetrics.precision(l))\n",
    "}\n",
    "\n",
    "// Recall by label\n",
    "labels.foreach { l =>\n",
    "  println(s\"Recall($l) = \" + mMetrics.recall(l))\n",
    "}\n",
    "\n",
    "// False positive rate by label\n",
    "labels.foreach { l =>\n",
    "  println(s\"FPR($l) = \" + mMetrics.falsePositiveRate(l))\n",
    "}\n",
    "\n",
    "// F-measure by label\n",
    "labels.foreach { l =>\n",
    "  println(s\"F1-Score($l) = \" + mMetrics.fMeasure(l))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 1.0, Precision: 1.0\n",
      "Threshold: 0.0, Precision: 0.0012986475303947984\n",
      "Threshold: 1.0, Recall: 0.9943502824858758\n",
      "Threshold: 0.0, Recall: 1.0\n",
      "Threshold: 0.0, F-score: 0.002593926464592328, Beta = 1\n",
      "Threshold: 1.0, F-score: 0.9971671388101983, Beta = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "precision: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[925] at map at BinaryClassificationMetrics.scala:214\n",
       "recall: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[926] at map at BinaryClassificationMetrics.scala:214\n",
       "PRC: org.apache.spark.rdd.RDD[(Double, Double)] = UnionRDD[929] at union at BinaryClassificationMetrics.scala:110\n",
       "f1Score: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[930] at map at BinaryClassificationMetrics.scala:214\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Precision by threshold\n",
    "val precision = bMetrics.precisionByThreshold\n",
    "precision.foreach { case (t, p) =>\n",
    "  println(s\"Threshold: $t, Precision: $p\")\n",
    "}\n",
    "\n",
    "// Recall by threshold\n",
    "val recall = bMetrics.recallByThreshold\n",
    "recall.foreach { case (t, r) =>\n",
    "  println(s\"Threshold: $t, Recall: $r\")\n",
    "}\n",
    "\n",
    "// Precision-Recall Curve\n",
    "val PRC = bMetrics.pr\n",
    "\n",
    "// F-measure\n",
    "val f1Score = bMetrics.fMeasureByThreshold\n",
    "f1Score.foreach { case (t, f) =>\n",
    "  println(s\"Threshold: $t, F-score: $f, Beta = 1\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.0, F-score: 0.002593926464592328, Beta = 0.5\n",
      "Threshold: 1.0, F-score: 0.9971671388101983, Beta = 0.5\n",
      "Area under precision-recall curve = 0.9971788097387865\n",
      "Area under ROC = 0.9971751412429379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "beta: Double = 0.5\n",
       "fScore: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[931] at map at BinaryClassificationMetrics.scala:214\n",
       "auPRC: Double = 0.9971788097387865\n",
       "thresholds: org.apache.spark.rdd.RDD[Double] = MapPartitionsRDD[937] at map at <console>:53\n",
       "roc: org.apache.spark.rdd.RDD[(Double, Double)] = UnionRDD[941] at UnionRDD at BinaryClassificationMetrics.scala:90\n",
       "auROC: Double = 0.9971751412429379\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val beta = 0.5\n",
    "val fScore = bMetrics.fMeasureByThreshold(beta)\n",
    "f1Score.foreach { case (t, f) =>\n",
    "  println(s\"Threshold: $t, F-score: $f, Beta = 0.5\")\n",
    "}\n",
    "\n",
    "// AUPRC\n",
    "val auPRC = bMetrics.areaUnderPR\n",
    "println(\"Area under precision-recall curve = \" + auPRC)\n",
    "\n",
    "// Compute thresholds used in ROC and PR curves\n",
    "val thresholds = precision.map(_._1)\n",
    "\n",
    "// ROC Curve\n",
    "val roc = bMetrics.roc\n",
    "\n",
    "// AUROC\n",
    "val auROC = bMetrics.areaUnderROC\n",
    "println(\"Area under ROC = \" + auROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.- Do we have a representative test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important assumption is that the statistical distributions we are learning from are the same in the training and test sets. We will use the are under the ROC curve as a measure of the similitude of these distributions: if they are indeed similar, the area below the ROC should be close to 0.5, indicating non-separability between the \"training\" and \"testing\" classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data2_ver: org.apache.spark.sql.DataFrame = [amount: double, oldbalanceOrg: double ... 8 more fields]\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// renaming the \"label\" column\n",
    "val data2_ver = data2.withColumnRenamed(\"label\", \"label_orig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_tmp: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [amount: double, oldbalanceOrg: double ... 8 more fields]\n",
       "test_tmp: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [amount: double, oldbalanceOrg: double ... 8 more fields]\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// train/test split for verification purposes\n",
    "val Array(train_tmp, test_tmp) = data2_ver.randomSplit(Array(0.7, 0.3), seed = 801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_ver: org.apache.spark.sql.DataFrame = [amount: double, oldbalanceOrg: double ... 9 more fields]\n",
       "test_ver: org.apache.spark.sql.DataFrame = [amount: double, oldbalanceOrg: double ... 9 more fields]\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// add a \"fake label\" to distinguish train & test sets\n",
    "val train_ver = train_tmp.withColumn(\"label\", lit(1))\n",
    "val test_ver = test_tmp.withColumn(\"label\", lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_ver0: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [amount: double, oldbalanceOrg: double ... 9 more fields]\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// append train and test sets\n",
    "val df_ver0 = train_ver.unionAll(test_ver).orderBy(rand()).orderBy(rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_be13c94415cd\n",
       "df_ver1: org.apache.spark.sql.DataFrame = [label: int, features: vector]\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// assemble features vector\n",
    "val assembler = (new VectorAssembler().setInputCols(Array(\"amount\", \"oldbalanceOrg\", \n",
    "    \"newbalanceOrig\", \"oldbalanceDest\", \"newbalanceDest\", \"emptiedAccount\", \"zeroBalance\", \n",
    "    \"originBalanceDiff\", \"recipientBalanceDiff\", \"label_orig\")).\n",
    "   setOutputCol(\"features\"))\n",
    "\n",
    "// Transform the DataFrame\n",
    "val df_ver1 = assembler.transform(df_ver0).select($\"label\",$\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf_ver: org.apache.spark.ml.classification.RandomForestClassifier = rfc_d04989db0114\n",
       "paramGrid_ver: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\trfc_50246d962f4e-maxBins: 100,\n",
       "\trfc_50246d962f4e-numTrees: 20\n",
       "})\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// invoke random forests classifier\n",
    "val rf_ver = new RandomForestClassifier()\n",
    "\n",
    "val paramGrid_ver = new ParamGridBuilder().addGrid(rf.numTrees, Array(20)).addGrid(rf.maxBins, Array(100)).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv_ver: org.apache.spark.ml.tuning.CrossValidator = cv_c01a65de6d2d\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cv_ver = new CrossValidator().\n",
    "  setEstimator(rf_ver).\n",
    "  setEvaluator(new BinaryClassificationEvaluator().setMetricName(\"areaUnderROC\")).\n",
    "  setEstimatorParamMaps(paramGrid_ver).\n",
    "  setNumFolds(5).\n",
    "  setParallelism(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_ver: org.apache.spark.ml.tuning.CrossValidatorModel = cv_c01a65de6d2d\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model_ver = cv_ver.fit(df_ver1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res11: Array[Double] = Array(0.499694051371576)\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ver.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and test sets have similar statistical distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
